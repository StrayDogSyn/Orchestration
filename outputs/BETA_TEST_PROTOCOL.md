# Lecture 01 Beta Testing Protocol
**For: Hunter Hall (Self-Test)**

---

## ðŸŽ¯ Objective

Test Lecture 01 as if you're a student with:
- 6 months of prior coding experience
- Bootcamp grad level (OOP, basic algorithms)
- Some AI tool exposure but no formal training
- Realistic time constraints (busy schedule, competing priorities)

**Goal**: Find friction, confusion, and "I'd give up here" moments BEFORE real students encounter them.

---

## ðŸ“‹ Pre-Test Setup (5 minutes)

### Environment Prep

1. **Clear your context**:
   ```bash
   # Close all browser tabs related to this project
   # Open ONLY:
   - modules/01-foundations/lectures/01-architects-advantage.md
   - modules/01-foundations/labs/lab-01-fix-ai-homework/starter.md
   - A blank text editor for notes
   ```

2. **Set timers**:
   - Total timer: 50 minutes (lecture estimate)
   - Section timers: 6min video, 8min quiz, 28min lab, 8min reflection

3. **Prepare logging**:
   ```markdown
   # Beta Test Log - Lecture 01
   **Date**: [YYYY-MM-DD]
   **Start Time**: [HH:MM]
   
   ## Section Timers
   - Concept Video: Started [HH:MM] | Ended [HH:MM] | Duration: ___
   - Quiz: Started [HH:MM] | Ended [HH:MM] | Duration: ___
   - Lab: Started [HH:MM] | Ended [HH:MM] | Duration: ___
   - Reflection: Started [HH:MM] | Ended [HH:MM] | Duration: ___
   
   ## Friction Log
   [Keep this open while testing - log issues in real-time]
   ```

---

## ðŸ§ª Test Execution

### Part 1: Concept Video Script (Target: 6 minutes)

**What You're Testing**:
- Does the Chinese Room analogy make sense on first read?
- Is the "Old vs New Paradigm" table clear?
- Do the 4 sections flow logically?

**How to Test**:
1. Read the "Concept Video" section at normal reading speed (don't skim)
2. After each subsection, pause and ask:
   - "Could I explain this to someone else?"
   - "Do I buy the argument?"
   - "Is there jargon I don't understand?"

**Capture**:
```markdown
### Video Script Feedback

**Subsection 1: Opening Hook**
- Clarity (1-5): ___
- Engagement (1-5): ___
- Issues: 

**Subsection 2: Chinese Room**
- Did the analogy click? YES / NO / SORT OF
- If NO, why:

**Subsection 3: Paradigm Shift**
- Is the table helpful? YES / NO
- Which row resonated most:
- Which row was confusing:

**Subsection 4: Foundation Thesis**
- Does "Fundamentals Ã— AI = Superpowers" work as a tagline? YES / NO
- Better alternative:
```

---

### Part 2: Active Recall Quiz (Target: 8 minutes)

**What You're Testing**:
- Are the questions at the right difficulty level?
- Do the explanations actually teach, or just reveal answers?
- Can you complete this in <8 minutes?

**How to Test**:
1. Answer each question WITHOUT revealing the answer first
2. THEN click to reveal and compare your answer
3. If you got it wrong, was the explanation helpful?

**Capture**:
```markdown
### Quiz Feedback

**Question 1: The Room Test**
- Your answer: ___
- Correct? YES / NO
- If wrong, did the explanation help you understand? YES / NO
- Time spent: ___ minutes

**Question 2: The Verification Test**
- Your answer: ___
- Correct? YES / NO
- Gotcha factor (1-5): ___ (1=too easy, 5=unfair trick question)
- Comment:

**Question 3: The Prompt Quality Test**
- Your answer: ___
- Correct? YES / NO
- Did this change how you think about prompting? YES / NO

**Question 4: The Identity Question**
- Your answer: 
- Reveal sample answer - how does yours compare:
- Did this make you think? YES / NO / MEH
```

---

### Part 3: Hands-On Lab (Target: 28 minutes)

**What You're Testing**:
- Can you complete all 7 tasks in 28 minutes?
- Are the instructions clear enough?
- Does the "architect's prompt" guidance actually help?
- Do you feel like you LEARNED something or just followed steps?

**How to Test**:
1. Open `starter.md` in a separate window
2. Actually DO the lab - don't just read it
3. Use ChatGPT or Claude for Task 3 (the prompt task)
4. Run the code (Python REPL, Jupyter, or just trace mentally)
5. LOG every moment you go "wait, what?"

**Capture**:
```markdown
### Lab Feedback

**Task 1: Complexity Analysis**
- Time spent: ___ minutes
- Got it right? YES / NO
- If wrong, what was confusing:

**Task 2: Architect's Diagnosis**
- Time spent: ___ minutes
- Knew the answer (dictionary)? YES / NO / GUESSED
- If guessed, what helped you figure it out:

**Task 3: The Architect's Prompt**
- Your prompt (paste it):


- AI's response quality (1-5): ___
- Did AI explain WHY or just give code: EXPLAINED / JUST CODE
- Would you have written a better prompt with more guidance: YES / NO

**Task 4-6: Testing**
- Could you run the code? YES / NO / FAKED IT
- If faked it, why:
- Did you see the performance difference? YES / NO / UNCLEAR

**Task 7: Verification Questions**
- Time spent: ___ minutes
- Did these questions feel redundant or valuable: REDUNDANT / VALUABLE
- Most valuable question:

**Overall Lab Experience**:
- Fun factor (1-5): ___
- Learning factor (1-5): ___
- "I'd recommend this to a friend" (1-5): ___
- Biggest blocker:
- Biggest "aha":
```

---

### Part 4: Reflection (Target: 6 minutes)

**What You're Testing**:
- Are the prompts thought-provoking or just busy-work?
- Do they reinforce the "architect mindset" or feel forced?
- Can you answer them authentically in the time allotted?

**How to Test**:
1. Set a 6-minute timer
2. Answer all 3 prompts as if you're submitting for a grade
3. Don't overthink - write what comes naturally

**Capture**:
```markdown
### Reflection Feedback

**Reflection 1: The Architect Test**
- Your answer:


- Time spent: ___ minutes
- Felt authentic or forced: AUTHENTIC / FORCED
- If forced, why:

**Reflection 2: The Verification Test**
- Your answer:


- Time spent: ___ minutes
- Did this prompt add value beyond the lab: YES / NO

**Reflection 3: The Growth Test**
- Your answer:


- Time spent: ___ minutes
- Is this a fair comparison (frameworks vs fundamentals): YES / NO / STRAWMAN

**Overall Reflection Experience**:
- Valuable or busy-work: VALUABLE / BUSY-WORK
- Prompted genuine thought: YES / NO / SORT OF
- Would you skip this section if not graded: YES / NO / MAYBE
```

---

## ðŸ“Š Post-Test Analysis (10 minutes)

### The Big Questions

Answer these AFTER completing all 4 sections:

```markdown
## Summary Assessment

### Time Analysis
- Total time spent: ___ minutes
- Estimate was: 50 minutes
- Delta: +/- ___ minutes
- Acceptable range (40-60 min)? YES / NO

### Emotional Journey
Where were you most:
- **Confused**: [Section + specific moment]
- **Engaged**: [Section + specific moment]
- **Bored**: [Section + specific moment]
- **Frustrated**: [Section + specific moment]

### The Cliff Test
"At what point would 22-year-old Hunter have given up?"
- Section: 
- Reason:
- What would've prevented that:

### The Recommend Test
"Would you recommend this lecture to your past self (6 months of coding experience)?"
- YES / NO / MAYBE
- Why:


### The Identity Test
"Do you feel more like an 'AI architect' now than before starting?"
- YES / NO / A LITTLE
- What convinced you (or didn't):


### Critical Issues (Showstoppers)
Issues that MUST be fixed before publishing:
1. 
2. 
3. 

### Nice-to-Haves (Enhancements)
Issues that would improve but aren't deal-breakers:
1. 
2. 
3. 

### Surprising Wins
Things that worked better than expected:
1. 
2. 
3. 
```

---

## ðŸ”§ Issue Severity Classification

Use this rubric when logging issues:

| Severity | Definition | Example |
|----------|------------|---------|
| **P0 - Critical** | Blocks learning completely | Code doesn't run, concept is wrong, instructions are incomprehensible |
| **P1 - High** | Causes significant confusion or time loss | Jargon not defined, time estimate way off, unclear success criteria |
| **P2 - Medium** | Suboptimal UX but workaroundable | Better analogy exists, instructions could be clearer, pacing feels off |
| **P3 - Low** | Nice-to-have improvements | Typo, bonus content suggestion, formatting tweak |

**Triage Rule**: Fix all P0/P1 before moving to Lecture 02. P2/P3 can wait.

---

## ðŸ“ Deliverables

After completing the beta test, export:

1. **Completed Beta Test Log** (all timestamps, friction points, feedback)
2. **Your actual lab answers** (the starter.md file you filled out)
3. **Issue Tracker** (table of all P0/P1/P2/P3 issues identified)
4. **Go/No-Go Recommendation**:
   - âœ… **GO**: Lecture is ready for real students (with minor revisions)
   - âš ï¸ **GO WITH FIXES**: Needs specific changes but core concept works
   - âŒ **NO-GO**: Fundamental issues require redesign

---

## â±ï¸ Time Budget

| Activity | Time |
|----------|------|
| Setup | 5 min |
| Concept Video Test | 8 min |
| Quiz Test | 10 min |
| Lab Test | 35 min |
| Reflection Test | 8 min |
| Post-Test Analysis | 10 min |
| **Total** | **76 minutes** |

**Note**: This is MORE than the 50-minute lecture because you're testing + logging, not just learning.

---

## ðŸš¦ Success Criteria

This beta test is successful if:

- âœ… You complete all sections (even if you hit friction)
- âœ… You log every moment of confusion in real-time
- âœ… You provide a honest GO/NO-GO recommendation
- âœ… You identify at least 3 concrete improvements (there will be issuesâ€”that's the point!)

---

**Ready?** Set your timer and begin! ðŸš€

---

**Created**: December 23, 2025  
**For**: Hunter Hall  
**Purpose**: Validate Lecture 01 before building more infrastructure
